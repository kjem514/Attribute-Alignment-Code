{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Alignment Code",
    "\n",
    "The code below will calculate the alignment of any number of attributes. It produces overall alignment values and pairwise distances between each set of attributes. Further, it calculates overall alignment in terms of average distance, potential energy of the system, and singular value decomposition (SVD) as described in detail in Emich, Lu, Ferguson, Peterson, & McCourt (2023, Organizational Research Methods). \n",
    "\n",
    "So, for example, if you want to calculate the alignment between attributes A, B, and C, it will return three A-B-C alignment scores (again, average distance, potential energy, and SVD) and three pairwise alignment scores (A-B, A-C, B-C). \n",
    "\n",
    "### STEP 1: To begin, please make sure that the red letters reading 'OverallGroupID' are changed to the column name that you have given to differentiate your teams. Normally, this is something like TeamID or GroupID.\n",
    "\n",
    "### STEP 2: Then, run the first cell below to store the necessary functions in your computer. \n",
    "This cell shows how to use these functions to process your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import linregress\n",
    "from scipy.special import gamma\n",
    "from itertools import permutations, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# MINIMUM_DISTANCE_BASE is a quantity that helps make sure the difference between two vectors is never actually 0\n",
    "# This is a reasonable assumption under the belief that observations are made in the presence of noise\n",
    "# If we actually knew the distribution of the noise we could set this in an informed fashion\n",
    "# Without that, we can simply set this to a \"small\" number and then play around with it\n",
    "MINIMUM_DISTANCE_BASE = .001\n",
    "\n",
    "# Set TEAM_SIZE_SCALING = True to allow for the distance between larger teams to be scaled down\n",
    "TEAM_SIZE_SCALING = True\n",
    "\n",
    "def extract_columns(columns, all_data, team_id_name='OverallGroupID', outcome_column_name=None):\n",
    "    data_matrix = all_data.values\n",
    "    team_id_index = np.where(imported_data.columns == team_id_name)[0][0]\n",
    "    if outcome_column_name:\n",
    "        outcome_index = np.where(imported_data.columns == outcome_column_name)[0][0]\n",
    "        \n",
    "    results = {}\n",
    "    for row_num, row in enumerate(data_matrix):\n",
    "        team = int(row[team_id_index])\n",
    "        if team not in results:\n",
    "            results[team] = {'attribute_dict': {column: [] for column in columns}}\n",
    "        if outcome_column_name:\n",
    "            results[team][outcome_column_name] = row[outcome_index]\n",
    "        for column in sorted(columns):\n",
    "            results[team]['attribute_dict'][column].append(all_data[column][row_num])\n",
    "        results[team]['attributes'] = np.array([results[team]['attribute_dict'][column] for column in columns]).T\n",
    "        \n",
    "    return results\n",
    "\n",
    "def _determine_auxiliary_terms(attributes, minimum_distance_base, team_size_scaling):\n",
    "    d = len(attributes)\n",
    "    team_size_scaling_value = 1 / np.sqrt(d) if team_size_scaling else 1.0\n",
    "    minimum_distance = minimum_distance_base * gamma((d + 1) / 2) / gamma(d / 2) * team_size_scaling_value\n",
    "    return minimum_distance, team_size_scaling_value\n",
    "\n",
    "def compute_potential_energy(attributes, minimum_distance_base=MINIMUM_DISTANCE_BASE, team_size_scaling=TEAM_SIZE_SCALING):\n",
    "    minimum_distance, team_size_scaling_value = _determine_auxiliary_terms(attributes, minimum_distance_base, team_size_scaling)\n",
    "    distance_matrix = cdist(attributes.T, attributes.T)\n",
    "    d = np.fmax(distance_matrix * team_size_scaling_value, minimum_distance)\n",
    "    distances = d[np.where(np.triu(d, 1))]\n",
    "    return minimum_distance / len(distances) * np.sum(1 / distances)\n",
    "\n",
    "def compute_svd_alignment(attributes, minimum_distance_base=MINIMUM_DISTANCE_BASE, team_size_scaling=TEAM_SIZE_SCALING, num_draws=50, max_draws=10000):\n",
    "    minimum_distance, _ = _determine_auxiliary_terms(attributes, minimum_distance_base, team_size_scaling)\n",
    "    \n",
    "    # The team size is already accounted for in the Frobenius norm\n",
    "    # If we want to shut off the impact of team size, we multiply back in the \n",
    "    def _svd_alignment(x):\n",
    "        singular_values = np.linalg.svd(x, compute_uv=False)\n",
    "        team_size_scaling_value = (1.0 if not team_size_scaling else len(x)) / np.linalg.norm(x, ord='fro')\n",
    "        return singular_values[0] / singular_values[1] * team_size_scaling_value\n",
    "    \n",
    "    # Technically, the restriction to all positive values isn't necessary, but I think it makes sense\n",
    "    # The random_shift goes up to 2 * minimum_distance to allow a decent potential of convergence even for high alignment\n",
    "    vals = []\n",
    "    for _ in range(max_draws):\n",
    "        random_shift = np.random.uniform(-1, 1, size=attributes.shape)\n",
    "        random_shift = np.random.uniform(0, 2 * minimum_distance) * random_shift / np.sqrt(np.sum(random_shift ** 2, axis=0)[None, :])\n",
    "        shifted_attributes = np.fmax(attributes + random_shift, 0)\n",
    "        distance_matrix = cdist(shifted_attributes.T, shifted_attributes.T)\n",
    "        distances = distance_matrix[np.where(np.triu(distance_matrix, 1))]\n",
    "        if not all(distances > minimum_distance):\n",
    "            continue\n",
    "        \n",
    "        vals.append(_svd_alignment(shifted_attributes))\n",
    "        if len(vals) >= num_draws:\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError('SVD alignment falied to converge')\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "def compute_average_distance(attributes, minimum_distance_base=MINIMUM_DISTANCE_BASE, team_size_scaling=TEAM_SIZE_SCALING):\n",
    "    minimum_distance, team_size_scaling_value = _determine_auxiliary_terms(attributes, minimum_distance_base, team_size_scaling)\n",
    "    distance_matrix = cdist(attributes.T, attributes.T)\n",
    "    d = np.fmax(distance_matrix * team_size_scaling_value, minimum_distance)\n",
    "    distances = d[np.where(np.triu(d, 1))]\n",
    "    return 1 / len(distances) * np.sum(distances)\n",
    "\n",
    "def compute_pairwise_distances(attributes, minimum_distance_base=MINIMUM_DISTANCE_BASE, team_size_scaling=TEAM_SIZE_SCALING):\n",
    "    minimum_distance, team_size_scaling_value = _determine_auxiliary_terms(attributes, minimum_distance_base, team_size_scaling)\n",
    "    distances = []\n",
    "    for i1, i2 in combinations(np.arange(attributes.shape[1]), 2):\n",
    "        distances.append(np.linalg.norm(attributes[:, i1] - attributes[:, i2]))\n",
    "    return np.fmax(np.array(distances) * team_size_scaling_value, minimum_distance)\n",
    "\n",
    "def add_metrics(info, minimum_distance_base=MINIMUM_DISTANCE_BASE, team_size_scaling=TEAM_SIZE_SCALING):\n",
    "    for team_id, stuff in info.items():\n",
    "        attributes = stuff['attributes']\n",
    "        stuff['metrics'] = {\n",
    "            'energy': compute_potential_energy(attributes, minimum_distance_base, team_size_scaling),\n",
    "            'avg_dist': compute_average_distance(attributes, minimum_distance_base, team_size_scaling),\n",
    "            'svd': compute_svd_alignment(attributes, minimum_distance_base, team_size_scaling),\n",
    "            'pairwise': compute_pairwise_distances(attributes, minimum_distance_base, team_size_scaling),\n",
    "        }\n",
    "        \n",
    "def print_metrics(info, team_id_name='OverallGroupID', outcome_column_name='outcome', savefile=None, csv_sep='\\t', suppress_output=False):\n",
    "    header_printed = False\n",
    "    lines = []\n",
    "    def print_maybe(string):\n",
    "        if not suppress_output:\n",
    "            print(string)\n",
    "    \n",
    "    for team_id, stuff in info.items():\n",
    "        if not header_printed:\n",
    "            attribute_names = [attribute for attribute in stuff['attribute_dict'].keys()]\n",
    "            metric_names = [metric for metric in sorted(stuff['metrics'].keys()) if metric != 'pairwise']\n",
    "            s = [team_id_name, outcome_column_name]\n",
    "            s += metric_names\n",
    "            if 'pairwise' in stuff['metrics']:\n",
    "                for attribute_1, attribute_2 in combinations(attribute_names, 2):\n",
    "                    s.append('--'.join(['pairwise', attribute_1, attribute_2]))\n",
    "            s = csv_sep.join(s)\n",
    "            print_maybe(s)\n",
    "            lines.append(s)\n",
    "            header_printed = True\n",
    "        s = [team_id, stuff[outcome_column_name]] + [stuff['metrics'][metric] for metric in metric_names]\n",
    "        s += stuff['metrics']['pairwise'].tolist()\n",
    "        s = csv_sep.join((str(ss) for ss in s))\n",
    "        print_maybe(s)\n",
    "        lines.append(s)\n",
    "    \n",
    "    if savefile:\n",
    "        with open(savefile, 'w') as f:\n",
    "            f.writelines(l + '\\n' for l in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now stored the alignment functions in your computer. Now, it is time to fill in the variable names that you are interested in. To do this:\n",
    "\n",
    "### STEP 3A: Fill in your file names. Put the name of your .csv data file where 'INGRoup Sample Data 7-21-23.csv' currently is. \n",
    "\n",
    "### STEP 3B: (Optional): If you would like to store your data in a separate .csv file, put what you would like to call that file where 'where-i-store-alignment-values.csv' currently is. \n",
    "\n",
    "### STEP 3C: Make sure suppress_output=False below (It should already be set to false). \n",
    "\n",
    "### STEP 4: Set the outcome_column_name to an outcome you are interested in. This command must have a value. If you simply want to create the alignment values without linking them to an outcome, just set this to your team ID variable. \n",
    "\n",
    "### STEP 5: * Replace `('attribute_0', 'attribute_1', 'attribute_2', 'attribute_3')` with whatever attributes you want to study. You can add or delete as many attributes as you wish. Just make sure all attributes are listed in the above format, with quotations around the attribute names and commas between them. \n",
    "\n",
    "### STEP 6: Then, copy/paste the data into Microsoft Excel and separate into columns where spaces appear:     - Data => Text to Columns => Delimited => Check \"space\" => Finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverallGroupID\tDV\tavg_dist\tenergy\tsvd\tpairwise--attribute_0--attribute_1\tpairwise--attribute_0--attribute_2\tpairwise--attribute_0--attribute_3\tpairwise--attribute_1--attribute_2\tpairwise--attribute_1--attribute_3\tpairwise--attribute_2--attribute_3\n",
      "1\t10.0\t0.0006646701940895684\t1.0\t3105.610254733011\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\n",
      "2\t8.0\t0.0006646701940895684\t1.0\t3285.347928341422\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\n",
      "3\t1.0\t1.821367205045918\t0.0003666100426682169\t1.2908805523355755\t1.7320508075688772\t2.0\t1.7320508075688772\t1.7320508075688772\t2.0\t1.7320508075688772\n",
      "4\t5.0\t1.3335548900646963\t0.3335548900646965\t3650.993881225854\t0.0006646701940895685\t2.0\t2.0\t2.0\t2.0\t0.0006646701940895685\n",
      "5\t9.0\t0.0006646701940895684\t1.0\t3269.826831683579\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\t0.0006646701940895685\n",
      "6\t6.0\t1.6200079035402937\t0.16695306236659954\t1.168224168262253\t0.0006646701940895685\t1.8708286933869707\t1.8708286933869707\t1.8708286933869707\t1.8708286933869707\t2.23606797749979\n",
      "7\t5.0\t1.6200079035402937\t0.16695306236659954\t1.168178575534993\t1.8708286933869707\t0.0006646701940895685\t1.8708286933869707\t1.8708286933869707\t2.23606797749979\t1.8708286933869707\n",
      "8\t6.0\t1.6200079035402937\t0.16695306236659951\t1.1682257542683305\t1.8708286933869707\t1.8708286933869707\t0.0006646701940895685\t2.23606797749979\t1.8708286933869707\t1.8708286933869707\n",
      "9\t4.0\t1.6200079035402937\t0.16695306236659951\t1.1682193217108898\t1.8708286933869707\t1.8708286933869707\t2.23606797749979\t0.0006646701940895685\t1.8708286933869707\t1.8708286933869707\n",
      "10\t5.0\t1.6200079035402937\t0.1669530623665995\t1.1681861096713932\t1.8708286933869707\t2.23606797749979\t1.8708286933869707\t1.8708286933869707\t0.0006646701940895685\t1.8708286933869707\n",
      "11\t5.0\t1.6200079035402934\t0.1669530623665995\t1.168238120291874\t2.23606797749979\t1.8708286933869707\t1.8708286933869707\t1.8708286933869707\t1.8708286933869707\t0.0006646701940895685\n",
      "12\t4.0\t1.0001107783656815\t0.16716516931223385\t4022.815322908872\t1.0\t1.0\t2.0\t0.0006646701940895685\t1.0\t1.0\n",
      "13\t3.0\t100.00011077836567\t0.16667165169312234\t3771.8496504757263\t100.0\t100.0\t200.0\t0.0006646701940895685\t100.0\t100.0\n"
     ]
    }
   ],
   "source": [
    "outcome_column_name = 'DV'\n",
    "attributes_to_study = ('attribute_0', 'attribute_1', 'attribute_2', 'attribute_3')\n",
    "\n",
    "imported_data = pandas.read_csv('INGRoup Sample Data 7-21-23.csv', index_col=False, sep=',')\n",
    "results = extract_columns(attributes_to_study, imported_data, outcome_column_name=outcome_column_name)\n",
    "add_metrics(results)\n",
    "# Set suppress_output=False to print to screen\n",
    "print_metrics(results, savefile='where-i-store-alignment-values.csv', suppress_output=False, outcome_column_name=outcome_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
