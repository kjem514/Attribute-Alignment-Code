{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, linregress\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import combinations\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_FILE = 'DataSetName.csv'\n",
    "TEAM_ID_COLUMN_INDEX = 1 # Recall that Python indexes from 0\n",
    "IMPORTED_DATA = pandas.read_csv(DATA_FILE, index_col=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with different sized data\n",
    "\n",
    "In order to deal with data from different sized teams, we're going to divide out the size of the team from the vector $\\mathbf{x}\\in\\mathbb{R}^d$.  This has the effect of normalizing vector sizes $\\mathbf{x}_\\text{norm} = \\frac{1}{d}\\mathbf{x}$.\n",
    "\n",
    "Note that this still does not completely account for issues where attributes are on totally different scales (if an attribute is roughly on the order of 5 and another is on the order of 50, then not all senses of distance are as effective).  But the impact of that is primarily in a statistical context: the mathematics still works as it should.\n",
    "\n",
    "Normalization is activated by default, but can be shut off by passing `normalize=False` to the comparison function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the definition of the relevant functions\n",
    "\n",
    "I can move these to a separate `.py` file to clean this notebook up some, but leaving things here makes it clear exactly what computation is happening.  It also allows us to make modifications on the fly (which shouldn't be needed but could be useful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns(columns, all_data=IMPORTED_DATA, team_id_column_index=TEAM_ID_COLUMN_INDEX):\n",
    "    data_matrix = all_data.to_numpy()\n",
    "    results = {}\n",
    "    for row_num, row in enumerate(data_matrix):\n",
    "        try:\n",
    "            team = int(row[TEAM_ID_COLUMN_INDEX])\n",
    "        except ValueError:\n",
    "            raise ValueError('Unable to convert team id to integer in row {0}: {1} ... is it an integer?'.format(row_num, row[TEAM_ID_COLUMN_INDEX]))\n",
    "        else:\n",
    "            if team != row[TEAM_ID_COLUMN_INDEX]:\n",
    "                raise ValueError('team in row {0} does not seem to be an integer: {1} ... should it be?'.format(row_num, row[TEAM_ID_COLUMN_INDEX]))\n",
    "        if team not in results:\n",
    "            results[team] = {column: [] for column in columns}\n",
    "        for column in columns:\n",
    "            results[team][column].append(all_data[column][row_num])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparisons_csv(base_column, comparison_columns, distance_type='cosine', all_data=IMPORTED_DATA, normalize=True):\n",
    "    assert type(base_column) == str\n",
    "    assert type(comparison_columns) == list and all([type(c) == str for c in comparison_columns])\n",
    "    results = extract_columns(set([base_column] + comparison_columns), all_data)\n",
    "    \n",
    "    print('Team  ' + base_column + ' vs.')\n",
    "    \n",
    "    max_header_length = max(map(len, comparison_columns))\n",
    "    header = '      '\n",
    "    types = ' '.join(['{' + str(i) + ':' + str(max_header_length) + 's}' for i in range(len(comparison_columns))])\n",
    "    header += types.format(*[str(d) for d in comparison_columns])\n",
    "    print(header)\n",
    "    print('-' * (5 + (max_header_length + 1) * len(comparison_columns) - 1))\n",
    "    \n",
    "    for team, info in sorted(results.items(), key=lambda x: x[0]):\n",
    "        c1 = numpy.array(info[base_column], dtype=float)\n",
    "        if normalize:\n",
    "            c1 /= len(c1)\n",
    "        results = []\n",
    "        for column in comparison_columns:\n",
    "            c2 = numpy.array(info[column], dtype=float)\n",
    "            if normalize:\n",
    "                c2 /= len(c2)\n",
    "            if distance_type == 'cosine':\n",
    "                results.append(numpy.arccos(numpy.dot(c1, c2) / (numpy.linalg.norm(c1) * numpy.linalg.norm(c2) + 1e-10)))\n",
    "            else:\n",
    "                results.append(numpy.linalg.norm(c1 - c2, ord=distance_type))\n",
    "        stuff = '{0:4d} '.format(int(team))\n",
    "        types = ' '.join(['{' + str(i) + ':' + str(max_header_length) + '.3f}' for i in range(len(comparison_columns))])\n",
    "        stuff += types.format(*results)\n",
    "        print(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team  cEXTRA vs.\n",
      "      cHEXEX   cSTAR    cCONTR   cPERF    ESTARscl\n",
      "-------------------------------------------------\n",
      " 102    0.277    0.414    0.582    0.583    0.340\n",
      " 103    0.154    0.311    0.271    0.232    0.223\n",
      " 104    0.426    0.658    0.400    0.465    0.411\n",
      " 105    0.292    0.543    0.322    0.335    0.263\n",
      " 106    0.416    0.490    0.368    0.331    0.376\n",
      " 107    0.120    0.620    0.719    0.748    0.322\n",
      " 108    0.426    0.466    0.635    0.454    0.384\n",
      " 109    0.416    0.308    0.732    0.734    0.382\n",
      " 110    0.220    0.560    0.465    0.478    0.392\n",
      " 111    0.254    0.352    0.244    0.214    0.241\n",
      " 112    0.473    0.128    0.208    0.124    0.119\n",
      " 113    0.426    0.255    0.236    0.212    0.230\n",
      " 114    0.384    0.427    0.407    0.374    0.307\n",
      " 115    0.347    2.145    1.777    1.761    1.259\n",
      " 116    0.293    0.380    0.272    0.248    0.261\n",
      " 117    0.229    0.577    0.568    0.641    0.383\n",
      " 118    0.328    0.562    0.454    0.410    0.383\n",
      " 119    0.217    0.349    0.521    0.576    0.389\n",
      " 120    0.378    0.128    0.259    0.277    0.145\n",
      " 121    0.360    0.438    0.301    0.398    0.378\n",
      " 122    0.416    0.530    0.474    0.379    0.401\n",
      " 123    0.336    0.341    0.177    0.082    0.201\n",
      " 124    0.229    0.390    0.390    0.385    0.275\n",
      " 125    0.349    0.182    0.260    0.284    0.082\n",
      " 126    0.680    0.181    0.284    0.316    0.030\n",
      " 127    0.216    0.402    0.376    0.365    0.287\n",
      " 128    0.319    0.489    0.392    0.435    0.392\n",
      " 129    0.266    0.515    0.383    0.392    0.355\n",
      " 130    0.193    0.429    0.463    0.552    0.343\n",
      " 131    0.183    0.566    0.389    0.402    0.467\n",
      " 132    0.222    0.635    0.573    0.567    0.447\n",
      " 133    0.161    0.296    0.237    0.259    0.214\n",
      " 134    0.373    0.772    0.698    0.629    0.479\n",
      " 135    0.261    0.395    0.409    0.353    0.393\n",
      " 136    0.347    0.333    0.339    0.376    0.296\n",
      " 137    0.035    0.462    0.672    0.447    0.361\n",
      " 138    0.315    0.469    0.368    0.238    0.370\n",
      " 139    0.360    0.432    0.678    0.695    0.405\n",
      " 140    0.029    0.331    0.228    0.181    0.180\n",
      " 141    0.357    0.281    0.111    0.219    0.219\n",
      " 142    0.224    0.463    0.254    0.259    0.284\n",
      " 143    0.344    1.384    1.263    1.281    0.756\n",
      " 144    0.297    0.437    0.399    0.421    0.299\n",
      " 145    0.239    0.341    0.254    0.318    0.191\n",
      " 146    0.289    0.371    0.385    0.184    0.086\n",
      " 147    0.304    0.211    0.306    0.334    0.142\n",
      " 148    0.337    0.377    0.317    0.328    0.271\n",
      " 149    0.541    1.679    1.340    1.323    0.871\n",
      " 150    0.265    1.036    0.890    0.845    0.632\n",
      " 151    0.248    0.375    0.086    0.159    0.306\n",
      " 152    0.202    0.423    0.274    0.202    0.324\n",
      " 153    0.332    0.260    0.188    0.212    0.133\n",
      " 154    0.221    0.900    0.654    0.694    0.673\n",
      " 155    0.149    0.499    0.246    0.229    0.399\n",
      " 156    0.354    1.398    1.131    1.111    0.724\n",
      " 157    0.292    0.737    0.473    0.488    0.435\n",
      " 158    0.447    0.413    0.462    0.453    0.323\n",
      " 159    0.226    0.288    0.387    0.341    0.287\n",
      " 160    0.120    0.437    0.543    0.576    0.381\n",
      " 163    0.148    0.401    0.233    0.269    0.208\n",
      " 164    0.750    0.763    0.685    0.780    0.685\n",
      " 165    0.405    0.699    0.531    0.552    0.512\n",
      " 166    0.188    1.703    1.385    1.372    0.932\n",
      " 167    0.241    0.206    0.232    0.355    0.198\n",
      " 168    0.384    0.926    0.687    0.796    0.637\n",
      " 169    0.193    0.574    0.419    0.445    0.427\n",
      " 170    0.248    1.542    1.252    1.256    0.872\n",
      " 171    0.372    0.385    0.399    0.504    0.267\n",
      " 172    0.363    0.474    0.242    0.344    0.222\n",
      " 173    0.352    0.376    0.423    0.414    0.273\n",
      " 174    0.150    0.459    0.407    0.396    0.289\n",
      " 175    0.212    0.459    0.559    0.462    0.362\n",
      " 176    0.309    0.530    0.478    0.458    0.332\n",
      " 177    0.225    0.301    0.202    0.154    0.154\n",
      " 178    0.274    1.693    1.434    1.422    0.895\n",
      " 179    0.258    0.656    0.289    0.315    0.236\n",
      " 180    0.217    0.311    0.404    0.349    0.269\n",
      " 181    0.391    0.702    1.362    1.353    0.529\n",
      " 182    0.320    0.756    0.826    0.814    0.393\n",
      " 183    0.260    0.376    0.318    0.246    0.198\n",
      " 184    0.303    0.568    0.537    0.390    0.371\n",
      " 185    0.363    0.472    0.407    0.341    0.290\n",
      " 186    0.831    0.886    0.895    0.878    0.810\n",
      " 187    0.269    1.431    1.156    1.141    0.774\n",
      " 188    0.150    0.405    0.450    0.497    0.345\n",
      " 189    0.551    1.680    1.359    1.311    0.796\n",
      " 190    0.464    0.381    0.382    0.434    0.311\n",
      " 191    0.412    1.456    1.178    1.167    0.924\n",
      " 192    0.466    1.098    0.908    0.729    0.683\n",
      " 193    0.259    0.373    0.341    0.332    0.265\n",
      " 194    0.293    1.595    1.312    1.303    0.932\n",
      " 195    0.406    0.285    0.326    0.168    0.210\n",
      " 196    0.286    0.647    0.669    0.658    0.432\n",
      " 197    0.324    0.689    0.270    0.359    0.376\n",
      " 198    0.176    1.346    1.046    0.956    0.669\n",
      " 199    0.250    0.593    0.318    0.249    0.352\n",
      " 200    0.337    0.961    0.848    0.818    0.595\n",
      " 201    0.265    0.305    0.286    0.229    0.231\n",
      " 202    0.265    0.378    0.267    0.305    0.293\n",
      " 203    0.505    0.650    0.558    0.526    0.567\n",
      " 204    0.234    0.261    0.169    0.227    0.219\n",
      " 205    0.073    0.938    0.689    0.737    0.492\n",
      " 206    0.214    0.252    0.284    0.201    0.191\n",
      " 207    0.138    0.330    0.157    0.204    0.166\n",
      " 208    0.189    0.292    0.326    0.287    0.214\n",
      " 209    0.302    0.834    0.737    0.695    0.483\n",
      " 210    0.205    0.417    0.279    0.294    0.324\n",
      " 211    0.115    0.122    0.192    0.197    0.115\n",
      " 212    0.567    1.013    0.786    0.873    0.708\n",
      " 213    0.268    0.359    0.144    0.181    0.211\n",
      " 214    0.077    0.242    0.298    0.320    0.181\n",
      " 215    0.234    0.702    0.508    0.541    0.403\n",
      " 216    0.217    0.398    0.220    0.236    0.229\n",
      " 217    0.221    0.380    0.177    0.185    0.238\n",
      " 218    0.189    0.518    0.307    0.295    0.282\n",
      " 219    0.168    0.360    0.238    0.267    0.275\n",
      " 220    0.224    0.585    0.468    0.469    0.274\n",
      " 221    0.183    0.887    0.647    0.663    0.476\n",
      " 222    0.217    0.487    0.225    0.164    0.140\n",
      " 223    0.238    1.141    0.867    0.674    0.648\n",
      " 224    0.210    0.429    0.599    0.342    0.307\n",
      " 225    0.281    1.120    0.697    0.620    0.629\n",
      " 226    0.248    0.451    0.295    0.215    0.311\n",
      " 301    0.194    0.497    0.417    0.406    0.375\n"
     ]
    }
   ],
   "source": [
    "base_column = 'Attribute1'\n",
    "comparison_columns = ['Attribute2','Attribute3','Attribute4','Attribute5', 'Attribute6']\n",
    "distance_type = 2\n",
    "\n",
    "\n",
    "print_comparisons_csv(base_column, comparison_columns, distance_type=distance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
